{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\" \n",
    "\n",
    "# 파이토치 사용할때 커널 충돌 문제 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = datasets.MNIST('MINIST_data', \n",
    "                             train = True, \n",
    "                             download=True, \n",
    "                             transform=transforms.Compose([transforms.ToTensor()])) # train data를 가져옴\n",
    "\n",
    "mnist_test = datasets.MNIST('MINIST_data', \n",
    "                             train = False, # False로 설정하면 test data를 가져옴\n",
    "                             download=True, \n",
    "                             transform=transforms.Compose([transforms.ToTensor()])) # test data를 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: MINIST_data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "           )\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: MINIST_data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(mnist_train)\n",
    "print(mnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 이미지 확인\n",
    "\n",
    "def plot(x): \n",
    "    img=(np.array(x.detach(), dtype='float')).reshape(28,28)\n",
    "    plt.imshow(img, cmap='grey')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(mnist_train.data[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "print(mnist_train.targets[10]) # tensor로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n",
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "print(mnist_train.targets[10])\n",
    "print(mnist_train.data.shape)\n",
    "print(mnist_train.targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  42, 118, 219,\n",
       "         166, 118, 118,   6,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 103, 242, 254, 254,\n",
       "         254, 254, 254,  66,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 232, 254, 254,\n",
       "         254, 254, 254, 238,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 104, 244, 254,\n",
       "         224, 254, 254, 254, 141,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 207, 254,\n",
       "         210, 254, 254, 254,  34,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  84, 206,\n",
       "         254, 254, 254, 254,  41,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24,\n",
       "         209, 254, 254, 254, 171,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  91, 137,\n",
       "         253, 254, 254, 254, 112,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  40, 214, 250, 254,\n",
       "         254, 254, 254, 254,  34,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  81, 247, 254, 254,\n",
       "         254, 254, 254, 254, 146,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 110, 246, 254,\n",
       "         254, 254, 254, 254, 171,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  73,  89,\n",
       "          89,  93, 240, 254, 171,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   1, 128, 254, 219,  31,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   7, 254, 254, 214,  28,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0, 138, 254, 254, 116,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  19, 177,  90,   0,   0,   0,   0,   0,\n",
       "          25, 240, 254, 254,  34,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0, 164, 254, 215,  63,  36,   0,  51,  89,\n",
       "         206, 254, 254, 139,   8,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  57, 197, 254, 254, 222, 180, 241, 254,\n",
       "         254, 253, 213,  11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0, 140, 105, 254, 254, 254, 254, 254,\n",
       "         254, 236,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   7, 117, 117, 165, 254, 254,\n",
       "         239,  50,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = mnist_train.data[10]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n",
      "784\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# 0 ~ 1 사이의 값으로 정규화\n",
    "\n",
    "x = mnist_train.data.float() / 255 # 데이터 스케일 조정\n",
    "#x[0] \n",
    "y = mnist_train.targets\n",
    "#y[:10] \n",
    "\n",
    "print(x.size())\n",
    "print(y.size())\n",
    "x=x.view(x.size(0),-1) # 2차원 데이터를 1차원으로 변환\n",
    "\n",
    "input_size = x.size(-1) # -1은 마지막 차원을 의미. 입력데이터 크기\n",
    "print(input_size) \n",
    "output_size=int(max(y))+1 # 제일 큰 값에 1을 더해줌 => 10. 출력데이터 크기\n",
    "print(output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 20 10000\n",
      "torch.Size([80, 1]) torch.Size([20, 1])\n",
      "torch.Size([80, 1]) torch.Size([20, 1])\n",
      "torch.Size([80, 1])\n",
      "torch.Size([20, 1])\n",
      "torch.Size([10000, 784])\n",
      "torch.Size([80, 1])\n",
      "torch.Size([20, 1])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "#훈련 데이터(train)와 검증 데이터(valid) 분리\n",
    "\n",
    "ratio = [0.8, 0.2] # 훈련 데이터와 검증 데이터 비율\n",
    "train_cnt=int(x.size(0)*ratio[0]) # 훈련 데이터 개수\n",
    "valid_cnt=int(x.size(0)*ratio[1]) # 검증 데이터 개수\n",
    "test_cnt=len(mnist_test.data) # 테스트 데이터 개수\n",
    "\n",
    "print(train_cnt, valid_cnt, test_cnt)\n",
    "cnts=[train_cnt, valid_cnt]\n",
    "\n",
    "indices=torch.randperm(x.size(0)) # 데이터 인덱스 섞기 위해 랜덤으로 섞음 \n",
    "\n",
    "#print(indices[0:20])\n",
    "\n",
    "x=torch.index_select(x, dim=0, index=indices) # 데이터 섞음\n",
    "y=torch.index_select(y, dim=0, index=indices) # y도 인덱스 맞춰서 섞음\n",
    "#plot(x[0]) # 데이터 확인 -> 섞인 데이터 확인 가능\n",
    "#y[0] # x[0]에 대한 y값 맞춰짐 \n",
    "\n",
    "x1=list(x.split(cnts, dim=0)) # 데이터 분할\n",
    "y1=list(y.split(cnts, dim=0)) # y값도 데이터 분할\n",
    "print(x1[0].shape, x1[1].shape) # 훈련, 검증, 테스트 데이터 개수 확인\n",
    "print(y1[0].shape, y1[1].shape) # 훈련, 검증, 테스트 데이터 개수 확인\n",
    "\n",
    "x1+=[(mnist_test.data.float()/255).view(test_cnt, -1)]\n",
    "y1+=[mnist_test.targets]\n",
    "\n",
    "for ii in x1:\n",
    "    print(ii.shape)\n",
    "\n",
    "for yi in y1:\n",
    "    print(yi.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=500, bias=True)\n",
       "  (1): LeakyReLU(negative_slope=0.01)\n",
       "  (2): Linear(in_features=500, out_features=400, bias=True)\n",
       "  (3): LeakyReLU(negative_slope=0.01)\n",
       "  (4): Linear(in_features=400, out_features=300, bias=True)\n",
       "  (5): LeakyReLU(negative_slope=0.01)\n",
       "  (6): Linear(in_features=300, out_features=200, bias=True)\n",
       "  (7): LeakyReLU(negative_slope=0.01)\n",
       "  (8): Linear(in_features=200, out_features=100, bias=True)\n",
       "  (9): LeakyReLU(negative_slope=0.01)\n",
       "  (10): Linear(in_features=100, out_features=50, bias=True)\n",
       "  (11): LeakyReLU(negative_slope=0.01)\n",
       "  (12): Linear(in_features=50, out_features=10, bias=True)\n",
       "  (13): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=nn.Sequential(\n",
    "    nn.Linear(input_size, 500), # 입력층\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(500, 400), # 은닉층 ( 앞의 값의 뒤 값과 은닉층 값의 앞 값이 같아야함)\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(400, 300),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(300, 200),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(200, 100),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(100, 50),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(50, output_size), # 출력층\n",
    "    nn.Softmax(dim=-1) # 출력층의 활성화 함수\n",
    ")\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "\n",
    "crit = nn.CrossEntropyLoss() # 손실함수\n",
    "optimizer = optim.Adam(model.parameters()) # 옵티마이저 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device) # 모델을 gpu로 보냄 -> cuda 사용할때 설정 필요\n",
    "x2=[x_i.to(device) for x_i in x1]\n",
    "y2=[y_i.to(device) for y_i in y1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련\n",
    "\n",
    "epochs = 1000\n",
    "batch_size = 256 # 배치 사이즈(한번에 학습시킬 데이터 양)\n",
    "print_interval = 10 # 출력 간격"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 데이터 넣었을때 가장 낮은 loss값을 가진 모델을 저장하기 위한 변수\n",
    "\n",
    "\n",
    "from copy import deepcopy # 모델 복사\n",
    "\n",
    "lowest_loss = np.inf # 가장 낮은 loss값을 저장하기 위한 변수 \n",
    "bast_model=None\n",
    "\n",
    "early_stop = 50  # 50번 이상 loss값이 증가하면 학습 종료 \n",
    "lowest_epoch = np.inf # 가장 낮은 loss값을 가진 epoch 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 62.],\n",
       "         [ 92.],\n",
       "         [ 86.],\n",
       "         [ 96.],\n",
       "         [144.],\n",
       "         [158.],\n",
       "         [194.],\n",
       "         [ 88.],\n",
       "         [ 90.],\n",
       "         [ 44.],\n",
       "         [ 12.],\n",
       "         [150.],\n",
       "         [ 40.],\n",
       "         [ 42.],\n",
       "         [172.],\n",
       "         [152.],\n",
       "         [108.],\n",
       "         [ 36.],\n",
       "         [ 94.],\n",
       "         [ 16.],\n",
       "         [104.],\n",
       "         [174.],\n",
       "         [ 68.],\n",
       "         [  8.],\n",
       "         [ 70.],\n",
       "         [ 98.],\n",
       "         [162.],\n",
       "         [196.],\n",
       "         [  2.],\n",
       "         [ 58.],\n",
       "         [110.],\n",
       "         [ 54.],\n",
       "         [148.],\n",
       "         [112.],\n",
       "         [182.],\n",
       "         [106.],\n",
       "         [156.],\n",
       "         [  6.],\n",
       "         [166.],\n",
       "         [ 78.],\n",
       "         [132.],\n",
       "         [124.],\n",
       "         [ 56.],\n",
       "         [ 14.],\n",
       "         [100.],\n",
       "         [ 22.],\n",
       "         [134.],\n",
       "         [ 26.],\n",
       "         [188.],\n",
       "         [130.],\n",
       "         [ 28.],\n",
       "         [ 80.],\n",
       "         [128.],\n",
       "         [  4.],\n",
       "         [ 38.],\n",
       "         [126.],\n",
       "         [178.],\n",
       "         [ 82.],\n",
       "         [ 34.],\n",
       "         [136.],\n",
       "         [ 60.],\n",
       "         [142.],\n",
       "         [160.],\n",
       "         [154.],\n",
       "         [186.],\n",
       "         [ 20.],\n",
       "         [146.],\n",
       "         [168.],\n",
       "         [  0.],\n",
       "         [ 76.],\n",
       "         [138.],\n",
       "         [ 84.],\n",
       "         [176.],\n",
       "         [ 74.],\n",
       "         [190.],\n",
       "         [ 72.],\n",
       "         [198.],\n",
       "         [140.],\n",
       "         [114.],\n",
       "         [192.]]),\n",
       " tensor([[ 50.],\n",
       "         [ 10.],\n",
       "         [ 18.],\n",
       "         [164.],\n",
       "         [ 30.],\n",
       "         [116.],\n",
       "         [118.],\n",
       "         [ 48.],\n",
       "         [ 52.],\n",
       "         [ 32.],\n",
       "         [122.],\n",
       "         [ 64.],\n",
       "         [ 24.],\n",
       "         [180.],\n",
       "         [102.],\n",
       "         [184.],\n",
       "         [ 66.],\n",
       "         [170.],\n",
       "         [ 46.],\n",
       "         [120.]]),\n",
       " tensor([7, 2, 1,  ..., 4, 5, 6])]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2[:10] # y값 확인 -> 1차원. 2차원으로 만들어야함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (80x1 and 784x500)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[105], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_i, y_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(x_, y_) : \u001b[38;5;66;03m# zip 함수를 사용하여 x와 y값을 묶어서 tensor로 변환\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     y_hat_i \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_i\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 모델에 x값 넣어서 y값 예측\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     loss \u001b[38;5;241m=\u001b[39m crit(y_hat_i, y_i\u001b[38;5;241m.\u001b[39msqueeze()) \u001b[38;5;66;03m# y_i를 2차원으로 만들어서 loss값 계산\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad() \u001b[38;5;66;03m# 기울기 초기화\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\it\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\it\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\it\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\it\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\it\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\it\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (80x1 and 784x500)"
     ]
    }
   ],
   "source": [
    "# 훈련 시작\n",
    "\n",
    "train_history, valid_history = [], []\n",
    "\n",
    "for i in range(epochs) :\n",
    "    indices=torch.randperm(x2[0].size(0)).to(device) # 데이터 섞기\n",
    "    x_=torch.index_select(x2[0], dim=0, index=indices) # x 훈련 데이터 섞음\n",
    "    y_=torch.index_select(y2[0], dim=0, index=indices) # y값도 섞음\n",
    "\n",
    "    x_=x_.split(batch_size, dim=0) # 배치 사이즈로 데이터 나눔\n",
    "    y_=y_.split(batch_size, dim=0) # 배치 사이즈로 y값 나눔\n",
    "\n",
    "    train_loss, valid_loss = 0, 0\n",
    "    y_hat = []\n",
    "\n",
    "    for x_i, y_i in zip(x_, y_) : # zip 함수를 사용하여 x와 y값을 묶어서 tensor로 변환\n",
    "        y_hat_i = model(x_i) # 모델에 x값 넣어서 y값 예측\n",
    "        loss = crit(y_hat_i, y_i.squeeze()) # y_i를 2차원으로 만들어서 loss값 계산\n",
    "\n",
    "        optimizer.zero_grad() # 기울기 초기화\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss+=float(loss) # loss값 계산\n",
    "\n",
    "    train_loss= train_loss/len(x_) # loss값 계산. len(x_)는 배치 사이즈로 나눈 값(4800/256)\n",
    "\n",
    "    with torch.no_grad(): # 검증 데이터는 기울기 계산 필요없음\n",
    "        x_=x2[1].split(batch_size, dim=0) # 검증 데이터 배치 사이즈로 나눔 -> 똑같은 사이즈로 만들기위해 \n",
    "        y_=y2[1].split(batch_size, dim=0) \n",
    "\n",
    "        for x_i, y_i in zip(x_, y_) :\n",
    "            y_hat_i=model(x_i) # 모델에 x값 넣어서 y값 예측\n",
    "            loss=crit(y_hat_i, y_i) # loss값 계산\n",
    "            valid_loss+=float(loss) \n",
    "\n",
    "            y_hat+=[y_hat_i] \n",
    "    valid_loss=valid_loss/len(x_i) # loss값 계산\n",
    "\n",
    "    train_history+= [train_loss] # 훈련 데이터 loss값 저장\n",
    "    valid_history+= [valid_loss] # 검증 데이터 loss값 저장\n",
    "\n",
    "    #출력\n",
    "    if (i+1) % print_interval == 0:\n",
    "        print(i, train_loss, valid_loss, lowest_loss) # epoch, 훈련 데이터 loss값, 검증 데이터 loss값 출력\n",
    "\n",
    "    if valid_loss <= lowest_loss: # 검증 데이터 loss값이 가장 낮을때 모델 저장\n",
    "        lowest_loss = valid_loss\n",
    "        lowest_epoch = i\n",
    "        bast_model = deepcopy(model.state_dict()) # 작은 값 구해질때마다 모델 저장\n",
    "\n",
    "\n",
    "\n",
    "      \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
